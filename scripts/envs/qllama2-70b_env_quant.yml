name: mlperf-qllama2-70b
channels:
  - defaults
dependencies:
  - python~=3.10.0
  - pip:
      -  --extra-index-url https://download.pytorch.org/whl/cu118
      -  torch==2.1.0+cu118
      -  absl-py==2.1.0
      -  git+https://github.com/furiosa-ai/accelerate-compression.git@4d7b404041834d35727064e5b1dcfcd060319ad6#egg=accelerate
      -  aiofiles==23.2.1
      -  aiohttp==3.8.6
      -  aiosignal==1.3.1
      -  async-timeout==4.0.3
      -  attrs==23.2.0
      -  boto3==1.34.67
      -  botocore==1.34.67
      -  certifi==2024.2.2
      -  charset-normalizer==3.3.2
      -  click==8.1.7
      -  cmake==3.28.3
      -  coloredlogs==15.0.1
      -  datasets==2.18.0
      -  dill==0.3.8
      -  evaluate==0.4.1
      -  filelock==3.13.1
      -  flatbuffers==24.3.7
      -  frozenlist==1.4.1
      -  fsspec==2024.2.0
      -  furiosa-common==0.10.1
      -  git+https://github.com/furiosa-ai/furiosa-llm-models.git@MLPerf4.1-v3.11
      -  furiosa-optimizer==0.10.0
      -  graphviz==0.20.3
      -  huggingface-hub==0.21.4
      -  humanfriendly==10.0
      -  idna==3.6
      -  Jinja2==3.1.3
      -  jmespath==1.0.1
      -  joblib==1.3.2
      -  lit==18.1.1
      -  markdown-it-py==3.0.0
      -  MarkupSafe==2.1.5
      -  mdurl==0.1.2
      -  git+https://github.com/furiosa-ai/model-compressor-private.git@MLPerf4.1-v3.11
      -  mpmath==1.3.0
      -  multidict==6.0.5
      -  multipledispatch==1.0.0
      -  multiprocess==0.70.16
      -  networkx==3.2.1
      -  nltk==3.8.1
      -  numpy==1.26.4
      -  nvidia-cublas-cu12==12.1.3.1
      -  nvidia-cuda-cupti-cu12==12.1.105
      -  nvidia-cuda-nvrtc-cu12==12.1.105
      -  nvidia-cuda-runtime-cu12==12.1.105
      -  nvidia-cudnn-cu12==8.9.2.26
      -  nvidia-cufft-cu12==11.0.2.54
      -  nvidia-curand-cu12==10.3.2.106
      -  nvidia-cusolver-cu12==11.4.5.107
      -  nvidia-cusparse-cu12==12.1.0.106
      -  nvidia-nccl-cu12==2.20.5
      -  nvidia-nvjitlink-cu12==12.5.40
      -  nvidia-nvtx-cu12==12.1.105
      -  onnx==1.14.1
      -  onnx-simplifier==0.4.36
      -  onnxoptimizer==0.3.13
      -  onnxruntime==1.15.1
      -  packaging==24.0
      -  pandas==2.2.1
      -  pillow==10.2.0
      -  protobuf==5.26.0
      -  psutil==5.9.8
      -  pyarrow==15.0.2
      -  pyarrow-hotfix==0.6
      -  pybind11==2.11.1
      -  pydot==2.0.0
      -  Pygments==2.17.2
      -  pyparsing==3.1.2
      -  python-dateutil==2.9.0.post0
      -  pytz==2024.1
      -  PyYAML==6.0.1
      -  regex==2023.12.25
      -  requests==2.31.0
      -  responses==0.18.0
      -  rich==13.7.1
      -  rouge_score==0.1.2
      -  ruamel.yaml==0.18.6
      -  ruamel.yaml.clib==0.2.8
      -  ruff==0.4.9
      -  s3transfer==0.10.1
      -  safetensors==0.4.2
      -  scipy==1.10.1
      -  sentencepiece==0.1.99
      -  simplejson==3.19.2
      -  six==1.16.0
      -  sympy==1.12
      -  timm==0.6.11
      -  tokenizers==0.13.3
      -  torch==2.1.0+cu118
      -  torchaudio==2.1.0+cu118
      -  torchvision==0.16.0+cu118
      -  tqdm==4.65.0
      -  git+https://github.com/furiosa-ai/transformers-comp.git@2b012fcf15006e2cb2b0d9735ebf5b1d08a744a8#egg=transformers
      -  triton==2.1.0
      -  typing==3.7.4.3
      -  typing_extensions==4.10.0
      -  tzdata==2024.1
      -  urllib3==2.2.1
      -  xxhash==3.4.1
      -  yarl==1.9.4